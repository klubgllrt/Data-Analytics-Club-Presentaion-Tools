{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMBD Scraper.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghbvg302ScOK",
        "colab_type": "text"
      },
      "source": [
        "#Web Scraping IMBD In Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjtv79nbT7iM",
        "colab_type": "text"
      },
      "source": [
        "**Web Scraping intro:**\n",
        "\n",
        "Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTAccGYL9fZj",
        "colab_type": "text"
      },
      "source": [
        "# Lets do it\n",
        "---\n",
        "*This activity provides a general workflow of integrating web scraping to extract movie information from IMBD*\n",
        "\n",
        "*See [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb) for an overview of using Colaboratory.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8RLvGv_n7OC",
        "colab_type": "text"
      },
      "source": [
        "## Set up the Python modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rtaqO6wr5oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.display import clear_output\n",
        "from time import time\n",
        "from time import sleep\n",
        "import pandas as pd\n",
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0HvQ8yrog8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pages = [str(i) for i in range(1,5)]\n",
        "years_url = [str(i) for i in range(2000,2018)]\n",
        "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y67U8RsDVr4n",
        "colab_type": "text"
      },
      "source": [
        "### Redeclaring the lists to store data in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpqgYMG_VdV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = []\n",
        "years = []\n",
        "imdb_ratings = []\n",
        "metascores = []\n",
        "votes = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMr8r6ORXABe",
        "colab_type": "text"
      },
      "source": [
        "## The Scraper\n",
        "Okay club, this next part gets hairy... But do not worry we will run through this step by step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLu5t6KPVhV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing the monitoring of the loop\n",
        "start_time = time()\n",
        "requests = 0\n",
        "\n",
        "# For every year in the interval 2000-2017\n",
        "for year_url in years_url:\n",
        "\n",
        "    # For every page in the interval 1-4\n",
        "    for page in pages:\n",
        "\n",
        "        # Make a get request\n",
        "        response = get('http://www.imdb.com/search/title?release_date=' + year_url +\n",
        "        '&sort=num_votes,desc&page=' + page, headers = headers)\n",
        "\n",
        "        # Pause the loop\n",
        "        sleep(randint(8,15))\n",
        "\n",
        "        # Monitor the requests\n",
        "        requests += 1\n",
        "        elapsed_time = time() - start_time\n",
        "        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
        "        clear_output(wait = True)\n",
        "\n",
        "        # Throw a warning for non-200 status codes\n",
        "        if response.status_code != 200:\n",
        "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
        "\n",
        "        # Break the loop if the number of requests is greater than expected\n",
        "        if requests > 72:\n",
        "            warn('Number of requests was greater than expected.')\n",
        "            break\n",
        "\n",
        "        # Parse the content of the request with BeautifulSoup\n",
        "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Select all the 50 movie containers from a single page\n",
        "        mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
        "\n",
        "        # For every movie of these 50\n",
        "        for container in mv_containers:\n",
        "            # If the movie has a Metascore, then:\n",
        "            if container.find('div', class_ = 'ratings-metascore') is not None:\n",
        "\n",
        "                # Scrape the name\n",
        "                name = container.h3.a.text\n",
        "                names.append(name)\n",
        "\n",
        "                # Scrape the year\n",
        "                year = container.h3.find('span', class_ = 'lister-item-year').text\n",
        "                years.append(year)\n",
        "\n",
        "                # Scrape the IMDB rating\n",
        "                imdb = float(container.strong.text)\n",
        "                imdb_ratings.append(imdb)\n",
        "\n",
        "                # Scrape the Metascore\n",
        "                m_score = container.find('span', class_ = 'metascore').text\n",
        "                metascores.append(int(m_score))\n",
        "\n",
        "                # Scrape the number of votes\n",
        "                vote = container.find('span', attrs = {'name':'nv'})['data-value']\n",
        "                votes.append(int(vote))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B8jOF6oXXfp",
        "colab_type": "text"
      },
      "source": [
        "###Sanity Check\n",
        "make sure it worked the way wer intended... *you should see 4 pages*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-cCC2OUQULg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z8WIvp8Gmn0",
        "colab_type": "text"
      },
      "source": [
        "### Import specialized Python libraries for working with data\n",
        "We will import two popular libraries for working with and graphing data in Python:\n",
        "\n",
        "* **Pandas** - a data analysis library ([Pandas user guide](http://pandas.pydata.org/pandas-docs/stable/user_guide/index.html))\n",
        "* **Matplotlib** - a Python 2D plotting library ([Matplotlib user guide](https://matplotlib.org/users/index.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEGQZXbsouhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok-iqmBejdVd",
        "colab_type": "text"
      },
      "source": [
        "### Reformatting data for graphing\n",
        "With a DataFrame we have access to functions to modify our dataset. We will remove unnecessary data fields (coulmns), edit existing fields, and create new data fields from existing fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOH--b5JyfAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_ratings = pd.DataFrame({'movie': names,\n",
        "'year': years,\n",
        "'imdb': imdb_ratings,\n",
        "'metascore': metascores,\n",
        "'votes': votes\n",
        "})\n",
        "print(movie_ratings.info())\n",
        "movie_ratings.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61XLp0kHyo8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_ratings = movie_ratings[['movie', 'year', 'imdb', 'metascore', 'votes']]\n",
        "movie_ratings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSZC7S8KywcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (16,4))\n",
        "ax1, ax2, ax3 = fig.axes\n",
        "ax1.hist(movie_ratings['imdb'], bins = 10, range = (0,10)) # bin range = 1\n",
        "ax1.set_title('IMDB rating')\n",
        "ax2.hist(movie_ratings['metascore'], bins = 10, range = (0,100)) # bin range = 10\n",
        "ax2.set_title('Metascore')\n",
        "ax3.hist(movie_ratings['imdb']*10, bins = 10, range = (0,100), histtype = 'step')\n",
        "ax3.hist(movie_ratings['metascore'], bins = 10, range = (0,100), histtype = 'step')\n",
        "ax3.legend(loc = 'upper left')\n",
        "ax3.set_title('The Two Normalized Distributions')\n",
        "for ax in fig.axes:\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p44iZ25GIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for container in mv_containers:\n",
        "  print(container.h3.a.text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}